{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pywt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code reads in a list of CSV files from the \"./dataset\" directory\n",
    "# and processes them by cleaning up any string columns, converting the\n",
    "# timestamp column to a numerical format, and saving the cleaned-up\n",
    "# data to the \"./processed\" directory\n",
    "\n",
    "datasets = os.listdir(\"./dataset\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Read in the CSV file\n",
    "    df = pd.read_csv(f\"./dataset/{dataset}\", header=None, delimiter=\" \")\n",
    "\n",
    "    # Clean up any string columns by removing '[' and ']' characters\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Check if column contains strings\n",
    "            df[col] = df[col].str.replace(']', '')\n",
    "            df[col] = df[col].str.replace('[', '')\n",
    "        elif df[col].dtype == 'int64':  # Check if column contains integers\n",
    "            raise ValueError(\"Cannot remove ']' from columns of integer type\")\n",
    "\n",
    "    # Drop the first column, which is not needed\n",
    "    df = df.drop(columns=[0])\n",
    "\n",
    "    # Rename the second and third columns to \"timestamp\" and \"Value\"\n",
    "    df = df.rename(columns={1: 'timestamp', 2: 'Value'})\n",
    "\n",
    "    # Convert the \"timestamp\" column to a timedelta format\n",
    "    df['timestamp'] = pd.to_timedelta(df['timestamp'])\n",
    "\n",
    "    # Convert the timedelta to seconds\n",
    "    df['timestamp'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "    # Remove any rows where the timestamp is equal to 0\n",
    "    df = df[df['timestamp']//1 != 0]\n",
    "\n",
    "    # Round the timestamp to the nearest 0.001 seconds\n",
    "    df['timestamp'] = df['timestamp'].round(3)\n",
    "\n",
    "    # Remove any duplicate rows\n",
    "    # df = df.drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "    # Save the cleaned-up data to the \"./processed\" directory\n",
    "    df.to_csv(f\"./processed/{dataset}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forwarda.csv\n",
      "forwardaa.csv\n",
      "forwardab.csv\n",
      "forwardac.csv\n",
      "forwardad.csv\n",
      "forwardae.csv\n",
      "forwardaf.csv\n",
      "forwardag.csv\n",
      "forwardah.csv\n",
      "forwardai.csv\n",
      "forwardaj.csv\n",
      "forwardb.csv\n",
      "forwardc.csv\n",
      "forwarde.csv\n",
      "forwardf.csv\n",
      "forwardg.csv\n",
      "forwardi.csv\n",
      "forwardj.csv\n",
      "forwardk.csv\n",
      "forwardl.csv\n",
      "forwardm.csv\n",
      "forwardn.csv\n",
      "forwardo.csv\n",
      "forwardp.csv\n",
      "forwardq.csv\n",
      "forwardr.csv\n",
      "forwards.csv\n",
      "forwardt.csv\n",
      "forwardv.csv\n",
      "forwardw.csv\n",
      "forwardx.csv\n",
      "forwardy.csv\n",
      "forwardz.csv\n",
      "lefta.csv\n",
      "leftaa.csv\n",
      "leftab.csv\n",
      "leftac.csv\n",
      "leftad.csv\n",
      "leftae.csv\n",
      "leftaf.csv\n",
      "leftag.csv\n",
      "leftah.csv\n",
      "leftai.csv\n",
      "leftb.csv\n",
      "leftc.csv\n",
      "lefte.csv\n",
      "leftf.csv\n",
      "leftg.csv\n",
      "lefti.csv\n",
      "leftj.csv\n",
      "leftk.csv\n",
      "leftl.csv\n",
      "leftm.csv\n",
      "leftn.csv\n",
      "lefto.csv\n",
      "leftp.csv\n",
      "leftq.csv\n",
      "leftr.csv\n",
      "lefts.csv\n",
      "leftt.csv\n",
      "leftv.csv\n",
      "leftw.csv\n",
      "leftx.csv\n",
      "lefty.csv\n",
      "leftz.csv\n",
      "righta.csv\n",
      "rightaa.csv\n",
      "rightab.csv\n",
      "rightac.csv\n",
      "rightad.csv\n",
      "rightae.csv\n",
      "rightaf.csv\n",
      "rightag.csv\n",
      "rightah.csv\n",
      "rightai.csv\n",
      "rightaj.csv\n",
      "rightb.csv\n",
      "rightc.csv\n",
      "righte.csv\n",
      "rightf.csv\n",
      "rightg.csv\n",
      "righti.csv\n",
      "rightj.csv\n",
      "rightk.csv\n",
      "rightl.csv\n",
      "rightm.csv\n",
      "rightn.csv\n",
      "righto.csv\n",
      "rightp.csv\n",
      "rightq.csv\n",
      "rightr.csv\n",
      "rights.csv\n",
      "rightt.csv\n",
      "rightv.csv\n",
      "rightw.csv\n",
      "rightx.csv\n",
      "righty.csv\n",
      "rightz.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Function to apply ATAR algorithm for artifact removal\n",
    "def artifact_removal(signal, threshold_mode='elimination', threshold_param=200, wavelet='db4', level=4):\n",
    "    # Perform wavelet decomposition\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    \n",
    "    # Apply ATAR algorithm\n",
    "    thresholded_coeffs = []\n",
    "    for i in range(len(coeffs)):\n",
    "        # Apply thresholding based on the chosen mode\n",
    "        if threshold_mode == 'elimination':\n",
    "            thresholded_coeffs.append(np.where(np.abs(coeffs[i]) <= threshold_param, coeffs[i], 0))\n",
    "        elif threshold_mode == 'linear_attenuation':\n",
    "            thresholded_coeffs.append(np.where(np.abs(coeffs[i]) <= threshold_param, coeffs[i], \n",
    "                                                np.sign(coeffs[i]) * threshold_param * (1 - np.abs(coeffs[i]) / threshold_param)))\n",
    "        elif threshold_mode == 'soft_thresholding':\n",
    "            alpha = -1 / threshold_param * np.log(threshold_param / (np.max(np.abs(coeffs[i])) + 1e-8))\n",
    "            thresholded_coeffs.append(np.where(np.abs(coeffs[i]) < threshold_param, coeffs[i], \n",
    "                                                np.sign(coeffs[i]) * (1 - np.exp(-alpha * np.abs(coeffs[i])))))\n",
    "    \n",
    "    # Reconstruct signal\n",
    "    cleaned_signal = pywt.waverec(thresholded_coeffs, wavelet)\n",
    "    \n",
    "    # Ensure the output signal has the same length as the input signal\n",
    "    cleaned_signal = cleaned_signal[:len(signal)]\n",
    "    \n",
    "    return cleaned_signal\n",
    "\n",
    "datasets = os.listdir(\"./dataset\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Read in the CSV file\n",
    "    df = pd.read_csv(f\"./dataset/{dataset}\", header=None, delimiter=\" \")\n",
    "\n",
    "    # Clean up any string columns by removing '[' and ']' characters\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Check if column contains strings\n",
    "            df[col] = df[col].str.replace(']', '')\n",
    "            df[col] = df[col].str.replace('[', '')\n",
    "        elif df[col].dtype == 'int64':  # Check if column contains integers\n",
    "            raise ValueError(\"Cannot remove ']' from columns of integer type\")\n",
    "\n",
    "    # Drop the first column, which is not needed\n",
    "    df = df.drop(columns=[0])\n",
    "    # Rename the second and third columns to \"timestamp\" and \"Value\"\n",
    "    df = df.rename(columns={1: 'timestamp', 2: 'Value'})\n",
    "\n",
    "    # Convert the \"timestamp\" column to a timedelta format\n",
    "    df['timestamp'] = pd.to_timedelta(df['timestamp'])\n",
    "\n",
    "    # Convert the timedelta to seconds\n",
    "    df['timestamp'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "    # Remove any rows where the timestamp is equal to 0\n",
    "    df = df[df['timestamp']//1 != 0]\n",
    "\n",
    "    # Round the timestamp to the nearest 0.001 seconds\n",
    "    df['timestamp'] = df['timestamp'].round(3)\n",
    "    \n",
    "    # Apply artifact removal to the 'Value' column\n",
    "    print(dataset)\n",
    "    df['Value'] = df['Value'].astype(float)\n",
    "\n",
    "    assert df['Value'].dtype == np.float64, \"Value column is not of float dtype after artifact removal\"\n",
    "    df['Value'] = artifact_removal(df['Value'])\n",
    "    \n",
    "    # Assert that the dtype of 'Value' column is float\n",
    "    \n",
    "    # Remove any duplicate rows\n",
    "    # df = df.drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "    # Save the cleaned-up data to the \"./processed\" directory\n",
    "    df.to_csv(f\"./processed/{dataset}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed/backwardb.csv\")\n",
    "\n",
    "index_to_drop = df.index[df['timestamp'] == 57.029][0]\n",
    "\n",
    "# Drop values until the index where 57.029 is encountered\n",
    "df = df.drop(range(index_to_drop))\n",
    "df['timestamp'] = (df['timestamp'] - df['timestamp'].iloc[0])\n",
    "df = df[df['timestamp']//1 != 0]\n",
    "df.to_csv(f\"./processed/backwardb.csv\", index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
